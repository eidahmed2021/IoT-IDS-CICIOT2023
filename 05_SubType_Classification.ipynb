{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìÖ Day 5: Level 3 ‚Äî 34-Class Sub-Type Classification\n",
                "## Full Granularity: All Attack Sub-Types + GPU Training\n",
                "\n",
                "---\n",
                "\n",
                "**Steps:**\n",
                "1. Load data\n",
                "2. Heavy imbalance handling (Undersample + SMOTE + Class weights)\n",
                "3. Train best model (XGBoost GPU)\n",
                "4. Per-class F1 deep dive\n",
                "5. Feature importance\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.add_dll_directory(r'C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v13.1\\bin\\x64')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "from sklearn.metrics import (accuracy_score, f1_score, classification_report, confusion_matrix)\n",
                "from sklearn.utils.class_weight import compute_sample_weight\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from imblearn.under_sampling import RandomUnderSampler\n",
                "from imblearn.pipeline import Pipeline as ImbPipeline\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import time\n",
                "import gc\n",
                "import json\n",
                "import joblib\n",
                "from datetime import datetime\n",
                "\n",
                "plt.style.use('dark_background')\n",
                "plt.rcParams['figure.figsize'] = (14, 6)\n",
                "plt.rcParams['font.size'] = 12\n",
                "\n",
                "os.makedirs('models', exist_ok=True)\n",
                "os.makedirs('figures', exist_ok=True)\n",
                "\n",
                "print(f\"‚úÖ Ready | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üì• Loading preprocessed data...\")\n",
                "t0 = time.time()\n",
                "\n",
                "X_train = np.load('processed/X_train.npy')\n",
                "X_test = np.load('processed/X_test.npy')\n",
                "y_train = np.load('processed/y_subtype_train.npy')\n",
                "y_test = np.load('processed/y_subtype_test.npy')\n",
                "\n",
                "with open('processed/preprocessing_metadata.json', 'r') as f:\n",
                "    meta = json.load(f)\n",
                "feature_names = meta['feature_names']\n",
                "subtype_classes = meta['subtype_classes']\n",
                "n_classes = len(subtype_classes)\n",
                "\n",
                "print(f\"‚úÖ Loaded in {time.time()-t0:.1f}s\")\n",
                "print(f\"   X_train: {X_train.shape} | X_test: {X_test.shape}\")\n",
                "print(f\"   Classes: {n_classes}\")\n",
                "\n",
                "# Class distribution\n",
                "print(f\"\\nüìä Training class distribution:\")\n",
                "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
                "for cls_id in class_counts.index:\n",
                "    count = class_counts[cls_id]\n",
                "    print(f\"   {cls_id:2d}: {subtype_classes[cls_id]:<35s} ‚Üí {count:>10,} ({count/len(y_train)*100:.3f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚öñÔ∏è Step 2: Heavy Imbalance Handling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Strategy: Undersample top-5 majority to 20K each, SMOTE minorities <500 up\n",
                "print(\"‚öñÔ∏è Applying imbalance handling pipeline...\")\n",
                "t0 = time.time()\n",
                "\n",
                "class_counts_dict = pd.Series(y_train).value_counts().to_dict()\n",
                "\n",
                "# Under-sampling: cap at 20K\n",
                "under_strategy = {}\n",
                "for cls_id, count in class_counts_dict.items():\n",
                "    if count > 20000:\n",
                "        under_strategy[cls_id] = 20000\n",
                "\n",
                "# Over-sampling: bring classes <500 up to 500  \n",
                "over_strategy = {}\n",
                "for cls_id, count in class_counts_dict.items():\n",
                "    effective_count = min(count, under_strategy.get(cls_id, count))\n",
                "    # Need at least k_neighbors+1 samples for SMOTE (default k=5, so need 6)\n",
                "    if effective_count < 500 and effective_count >= 6:\n",
                "        over_strategy[cls_id] = 500\n",
                "\n",
                "print(f\"   Under-sampling {len(under_strategy)} classes to 20K max\")\n",
                "print(f\"   Over-sampling {len(over_strategy)} classes to 500\")\n",
                "\n",
                "steps = []\n",
                "if under_strategy:\n",
                "    steps.append(('under', RandomUnderSampler(sampling_strategy=under_strategy, random_state=42)))\n",
                "if over_strategy:\n",
                "    steps.append(('over', SMOTE(sampling_strategy=over_strategy, random_state=42, k_neighbors=3, n_jobs=-1)))\n",
                "\n",
                "if steps:\n",
                "    pipeline = ImbPipeline(steps)\n",
                "    X_train_balanced, y_train_balanced = pipeline.fit_resample(X_train, y_train)\n",
                "    print(f\"   ‚úÖ Before: {len(y_train):,} | After: {len(y_train_balanced):,}\")\n",
                "else:\n",
                "    X_train_balanced, y_train_balanced = X_train, y_train\n",
                "    print(\"   ‚ö†Ô∏è No resampling applied\")\n",
                "\n",
                "print(f\"   ‚è±Ô∏è Done in {time.time()-t0:.1f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéÆ Step 3: Train XGBoost GPU ‚Äî 34-Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute sample weights on balanced data\n",
                "sample_weights = compute_sample_weight('balanced', y_train_balanced)\n",
                "\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"üéÆ XGBoost GPU ‚Äî 34-Class Sub-Type Classification\")\n",
                "print(f\"{'='*60}\")\n",
                "\n",
                "dtrain = xgb.DMatrix(X_train_balanced, label=y_train_balanced, weight=sample_weights, feature_names=feature_names)\n",
                "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=feature_names)\n",
                "\n",
                "del X_train_balanced, y_train_balanced\n",
                "gc.collect()\n",
                "\n",
                "xgb_params = {\n",
                "    'tree_method': 'hist',\n",
                "    'device': 'cuda',\n",
                "    'objective': 'multi:softprob',\n",
                "    'num_class': n_classes,\n",
                "    'eval_metric': ['mlogloss', 'merror'],\n",
                "    'max_depth': 10,\n",
                "    'learning_rate': 0.1,\n",
                "    'min_child_weight': 3,\n",
                "    'subsample': 0.8,\n",
                "    'colsample_bytree': 0.8,\n",
                "    'reg_alpha': 0.1,\n",
                "    'reg_lambda': 1.0,\n",
                "    'verbosity': 1,\n",
                "    'seed': 42\n",
                "}\n",
                "\n",
                "evals_result = {}\n",
                "t0 = time.time()\n",
                "bst = xgb.train(\n",
                "    xgb_params, dtrain,\n",
                "    num_boost_round=400,\n",
                "    evals=[(dtrain, 'train'), (dtest, 'test')],\n",
                "    early_stopping_rounds=25,\n",
                "    evals_result=evals_result,\n",
                "    verbose_eval=25\n",
                ")\n",
                "t_train = time.time() - t0\n",
                "\n",
                "y_pred_prob = bst.predict(dtest, iteration_range=(0, bst.best_iteration + 1))\n",
                "y_pred = y_pred_prob.argmax(axis=1)\n",
                "\n",
                "acc = accuracy_score(y_test, y_pred)\n",
                "f1_mac = f1_score(y_test, y_pred, average='macro')\n",
                "f1_wtd = f1_score(y_test, y_pred, average='weighted')\n",
                "\n",
                "print(f\"\\nüéÆ GPU Training Complete!\")\n",
                "print(f\"   ‚è±Ô∏è Time: {t_train:.1f}s ({t_train/60:.1f} min)\")\n",
                "print(f\"   üèÜ Best iteration: {bst.best_iteration}\")\n",
                "print(f\"   ‚úÖ Accuracy: {acc*100:.4f}%\")\n",
                "print(f\"   üéØ F1-Macro: {f1_mac*100:.4f}%\")\n",
                "print(f\"   üìè F1-Weighted: {f1_wtd*100:.4f}%\")\n",
                "\n",
                "bst.save_model('models/subtype_xgb_gpu.json')\n",
                "print(\"   üíæ Saved to models/subtype_xgb_gpu.json\")\n",
                "\n",
                "del dtrain; gc.collect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Also train LightGBM GPU for comparison\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"üéÆ LightGBM GPU ‚Äî 34-Class\")\n",
                "print(f\"{'='*60}\")\n",
                "\n",
                "# Reload balanced data for LightGBM\n",
                "# Use original data with class_weight since we deleted the balanced data\n",
                "lgb_train = lgb.Dataset(X_train, label=y_train, feature_name=feature_names, free_raw_data=False)\n",
                "lgb_test_ds = lgb.Dataset(X_test, label=y_test, feature_name=feature_names, reference=lgb_train, free_raw_data=False)\n",
                "\n",
                "lgb_params = {\n",
                "    'objective': 'multiclass',\n",
                "    'num_class': n_classes,\n",
                "    'metric': ['multi_logloss', 'multi_error'],\n",
                "    'device': 'gpu',\n",
                "    'gpu_use_dp': False,\n",
                "    'class_weight': 'balanced',\n",
                "    'max_depth': 10,\n",
                "    'learning_rate': 0.1,\n",
                "    'num_leaves': 200,\n",
                "    'min_child_samples': 20,\n",
                "    'subsample': 0.8,\n",
                "    'colsample_bytree': 0.8,\n",
                "    'reg_alpha': 0.1,\n",
                "    'reg_lambda': 1.0,\n",
                "    'verbosity': 1,\n",
                "    'seed': 42,\n",
                "    'n_jobs': -1\n",
                "}\n",
                "\n",
                "evals_lgb = {}\n",
                "t0 = time.time()\n",
                "bst_lgb = lgb.train(\n",
                "    lgb_params, lgb_train,\n",
                "    num_boost_round=400,\n",
                "    valid_sets=[lgb_train, lgb_test_ds],\n",
                "    valid_names=['train', 'test'],\n",
                "    callbacks=[\n",
                "        lgb.log_evaluation(50),\n",
                "        lgb.early_stopping(25),\n",
                "        lgb.record_evaluation(evals_lgb)\n",
                "    ]\n",
                ")\n",
                "t_train_lgb = time.time() - t0\n",
                "\n",
                "y_pred_lgb = bst_lgb.predict(X_test, num_iteration=bst_lgb.best_iteration).argmax(axis=1)\n",
                "\n",
                "acc_lgb = accuracy_score(y_test, y_pred_lgb)\n",
                "f1_mac_lgb = f1_score(y_test, y_pred_lgb, average='macro')\n",
                "\n",
                "print(f\"\\n   üéÆ GPU | ‚è±Ô∏è {t_train_lgb:.1f}s\")\n",
                "print(f\"   ‚úÖ Accuracy: {acc_lgb*100:.4f}% | F1-Macro: {f1_mac_lgb*100:.4f}%\")\n",
                "\n",
                "bst_lgb.save_model('models/subtype_lgb_gpu.txt')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Step 4: Per-Class F1 Deep Dive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Per-class report\n",
                "print(\"=\"*80)\n",
                "print(\"üìä 34-CLASS CLASSIFICATION REPORT\")\n",
                "print(\"=\"*80)\n",
                "print(classification_report(y_test, y_pred, target_names=subtype_classes, digits=4, zero_division=0))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Per-class F1 bar chart\n",
                "from sklearn.metrics import f1_score as f1\n",
                "\n",
                "per_class_f1 = f1_score(y_test, y_pred, average=None, zero_division=0)\n",
                "f1_df = pd.DataFrame({'Class': subtype_classes, 'F1-Score': per_class_f1})\n",
                "f1_df = f1_df.sort_values('F1-Score', ascending=True)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(14, 12))\n",
                "\n",
                "colors = plt.cm.RdYlGn(f1_df['F1-Score'].values)\n",
                "bars = ax.barh(f1_df['Class'], f1_df['F1-Score']*100, color=colors, edgecolor='white', linewidth=0.5)\n",
                "\n",
                "for bar, val in zip(bars, f1_df['F1-Score'].values):\n",
                "    ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2.,\n",
                "            f'{val*100:.1f}%', va='center', fontsize=9, color='white')\n",
                "\n",
                "ax.axvline(x=90, color='#FFD700', linestyle='--', alpha=0.5, label='90%')\n",
                "ax.axvline(x=50, color='#FF4C61', linestyle='--', alpha=0.5, label='50%')\n",
                "ax.set_xlim(0, 105)\n",
                "ax.set_title('üìä Per-Class F1-Score ‚Äî 34 Sub-Types', fontsize=16, fontweight='bold', color='#00D4AA')\n",
                "ax.set_xlabel('F1-Score (%)', fontsize=12)\n",
                "ax.legend(fontsize=10)\n",
                "ax.grid(True, axis='x', alpha=0.2)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('figures/subtype_per_class_f1.png', dpi=150, bbox_inches='tight', facecolor='#1a1a2e')\n",
                "plt.show()\n",
                "print(\"üíæ Saved to figures/subtype_per_class_f1.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix (34x34)\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "cm_pct = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(22, 18))\n",
                "\n",
                "sns.heatmap(cm_pct, annot=True, fmt='.0f', cmap='RdYlGn',\n",
                "            xticklabels=subtype_classes, yticklabels=subtype_classes,\n",
                "            ax=ax, linewidths=0.5, linecolor='gray',\n",
                "            annot_kws={'fontsize': 6}, cbar_kws={'label': 'Accuracy %'})\n",
                "ax.set_title('üìä 34-Class Confusion Matrix (% per class)', fontsize=16, fontweight='bold', color='#00D4AA')\n",
                "ax.set_xlabel('Predicted', fontsize=12)\n",
                "ax.set_ylabel('Actual', fontsize=12)\n",
                "ax.tick_params(axis='x', rotation=90, labelsize=8)\n",
                "ax.tick_params(axis='y', labelsize=8)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('figures/subtype_confusion_matrix.png', dpi=150, bbox_inches='tight', facecolor='#1a1a2e')\n",
                "plt.show()\n",
                "print(\"üíæ Saved to figures/subtype_confusion_matrix.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèÜ Step 5: Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance\n",
                "importance = bst.get_score(importance_type='weight')\n",
                "sorted_imp = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:15]\n",
                "\n",
                "imp_names = []\n",
                "imp_scores = []\n",
                "for fname, score in sorted_imp:\n",
                "    if fname.startswith('f'):\n",
                "        try:\n",
                "            fidx = int(fname[1:])\n",
                "            fname_actual = feature_names[fidx] if fidx < len(feature_names) else fname\n",
                "        except ValueError:\n",
                "            fname_actual = fname\n",
                "    else:\n",
                "        fname_actual = fname\n",
                "    imp_names.append(fname_actual)\n",
                "    imp_scores.append(score)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(12, 8))\n",
                "\n",
                "colors = plt.cm.plasma(np.linspace(0.2, 0.9, len(imp_names)))\n",
                "y_pos = range(len(imp_names) - 1, -1, -1)\n",
                "\n",
                "bars = ax.barh(y_pos, imp_scores, color=colors, edgecolor='white', linewidth=0.5, height=0.7)\n",
                "ax.set_yticks(y_pos)\n",
                "ax.set_yticklabels(imp_names, fontsize=11)\n",
                "\n",
                "for bar, score in zip(bars, imp_scores):\n",
                "    ax.text(bar.get_width() + max(imp_scores)*0.01, bar.get_y() + bar.get_height()/2.,\n",
                "            f'{score:.0f}', ha='left', va='center', fontsize=10, color='white')\n",
                "\n",
                "ax.set_title('üèÜ Top 15 Features ‚Äî 34-Class Classification', fontsize=16, fontweight='bold', color='#00D4AA')\n",
                "ax.set_xlabel('Importance Score (Weight)', fontsize=12)\n",
                "ax.grid(True, axis='x', alpha=0.2)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('figures/subtype_feature_importance.png', dpi=150, bbox_inches='tight', facecolor='#1a1a2e')\n",
                "plt.show()\n",
                "print(\"üíæ Saved to figures/subtype_feature_importance.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save results\n",
                "subtype_results = {\n",
                "    'timestamp': datetime.now().isoformat(),\n",
                "    'level': '34-Class SubType',\n",
                "    'device': 'GPU (CUDA)',\n",
                "    'xgboost': {'accuracy': float(acc), 'f1_macro': float(f1_mac), 'f1_weighted': float(f1_wtd), 'train_time': t_train},\n",
                "    'lightgbm': {'accuracy': float(acc_lgb), 'f1_macro': float(f1_mac_lgb), 'train_time': t_train_lgb},\n",
                "    'feature_importance_top15': [{'feature': n, 'score': float(s)} for n, s in zip(imp_names, imp_scores)],\n",
                "    'per_class_f1': {subtype_classes[i]: float(per_class_f1[i]) for i in range(n_classes)}\n",
                "}\n",
                "with open('models/subtype_results.json', 'w') as f:\n",
                "    json.dump(subtype_results, f, indent=2)\n",
                "\n",
                "print(\"\\nüèÜ\" * 20)\n",
                "print(f\"  ‚úÖ 34-CLASS CLASSIFICATION COMPLETE!\")\n",
                "print(f\"  üéÆ GPU Training | Accuracy: {acc*100:.2f}% | F1-Macro: {f1_mac*100:.2f}%\")\n",
                "print(\"üèÜ\" * 20)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}